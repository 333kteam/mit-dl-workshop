{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize youtube videos with natural language processing and automatic speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "import whisper\n",
    "from yt_dlp import YoutubeDL as YDL\n",
    "from transformers import AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The URL of the YouTube video to summarize\n",
    "YOUTUBE_URL = \"\"\n",
    "\n",
    "# The size of the ASR model to use\n",
    "ASR_MODEL_SIZE = \"small.en\"\n",
    "\n",
    "# The maximum length of each bullet point (in tokens)\n",
    "SUMMARY_LENGTH = 128\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Play around with other models at https://huggingface.co/models?pipeline_tag=summarization&sort=downloads\n",
    "NLP_ARCH = 'facebook/bart-large-cnn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_safe_filename(unsafe_string):\n",
    "    \"\"\"Replace all non-alphanumeric characters with underscores and return the modified string.\"\"\"\n",
    "    safe_string = re.sub(r'[^\\w\\s]', '_', unsafe_string)\n",
    "    safe_string = re.sub(r'_+', '_', safe_string)\n",
    "    safe_string = safe_string.strip('_')\n",
    "    return safe_string\n",
    "\n",
    "def save_transcript_to_csv(asr_result, file_path):\n",
    "    \"\"\"\n",
    "    Save transcription to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        asr_result: The transcription data to save.\n",
    "        file_path (str): The file path of the CSV file.\n",
    "    \"\"\"\n",
    "    field_names = ['start', 'end', 'text', 'summary']\n",
    "    with open(file_path, \"w\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for entry in asr_result:\n",
    "            writer.writerow({k:entry[k] for k in field_names if k in entry.keys()})\n",
    "\n",
    "def load_csv_to_transcript(file_path):\n",
    "    \"\"\"\n",
    "    Load transcription from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The file path of the CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        list: The transcription data.\n",
    "    \"\"\"\n",
    "    asr_result = []\n",
    "    with open(file_path, \"r\") as csv_file:\n",
    "        # Create a CSV reader\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            asr_result.append(row)\n",
    "    return asr_result\n",
    "\n",
    "def format_time(t):\n",
    "    \"\"\"\n",
    "    Convert a time in seconds to a string in HH:MM:SS format.\n",
    "    \n",
    "    Parameters:\n",
    "        t (str): The time in seconds.\n",
    "    \n",
    "    Returns:\n",
    "        str: The time in HH:MM:SS format.\n",
    "    \"\"\"\n",
    "    t = round(float(t))\n",
    "    hh = t // 3600\n",
    "    t %= 3600\n",
    "    mm = t // 60\n",
    "    ss = t % 60\n",
    "    return f\"{hh:02d}:{mm:02d}:{ss:02d}\"\n",
    "\n",
    "def print_timestamped_summaries(summary_file):\n",
    "    \"\"\"\n",
    "    Print timestamped summaries from a summary file.\n",
    "    \n",
    "    Parameters:\n",
    "        summary_file (str): The file path of the summary file.\n",
    "    \"\"\"\n",
    "    # Load the summary segments from the file\n",
    "    segments = load_csv_to_transcript(summary_file)\n",
    "    \n",
    "    # Iterate through the segments and print their start and end times and summaries\n",
    "    for seg in segments:\n",
    "        print(f\"{format_time(seg['start'])} - {format_time(seg['end'])}\")\n",
    "        print(seg['summary'])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the audio from a given youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_url: str):\n",
    "    \"\"\"\n",
    "    Download audio from an uploaded video.\n",
    "    \n",
    "    Parameters:\n",
    "        video_url (str): The URL of the video.\n",
    "    \n",
    "    Returns:\n",
    "        str: The file path of the audio file.\n",
    "    \"\"\"\n",
    "    # Create folder for assets\n",
    "    with YDL({'quiet':True}) as ydl:\n",
    "        dir_name = ydl.prepare_filename(ydl.extract_info(video_url, download=False)).split('.')[0]\n",
    "    dir_name = create_safe_filename(dir_name)\n",
    "    audio_path = f\"{dir_name}/audio.mp3\"\n",
    "\n",
    "    # Download audio file if it does not exist\n",
    "    if not os.path.exists(audio_path):\n",
    "        YDL_OPTS = {\n",
    "            'quiet':True,\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': audio_path,\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '128',\n",
    "        }]}\n",
    "        with YDL(YDL_OPTS) as ydl:\n",
    "            ydl.download([video_url])\n",
    "        \n",
    "    return audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = download_video(YOUTUBE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use an ASR model to transcribe the speech parts of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path: str, asr_model, transcript_path: str = None):\n",
    "    \"\"\"\n",
    "    Transcribe an audio file using the provided ASR model.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_path (str): The file path of the audio file.\n",
    "        asr_model: The ASR model to use for transcription.\n",
    "    \n",
    "    Returns:\n",
    "        str: The file path of the transcript.\n",
    "    \"\"\"\n",
    "    if transcript_path is None:\n",
    "        # Get the default transcript filepath\n",
    "        dir_name = os.path.dirname(audio_path)\n",
    "        transcript_path = f\"{dir_name}/transcript.csv\"\n",
    "\n",
    "    # Save the audio transcript as a csv file at the transcript filepath\n",
    "    if not os.path.exists(transcript_path):        \n",
    "        with torch.no_grad():\n",
    "            asr_result = asr_model.transcribe(audio_path)['segments']\n",
    "        save_transcript_to_csv(asr_result, transcript_path)\n",
    "        \n",
    "    return transcript_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = whisper.load_model(ASR_MODEL_SIZE).to(DEVICE)\n",
    "transcript_path = transcribe_audio(audio, asr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate summary of transcription\n",
    "- 2 bullet points on what tokenization is\n",
    "- overview of what this function does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_timestamps(asr_result: List[dict]):\n",
    "    \"\"\"\n",
    "    Tokenize transcribed text, chunking into segments of length NLP_MAXLEN \n",
    "    while preserving timestamps from ASR transcription.\n",
    "    \n",
    "    Parameters:\n",
    "        asr_result (List[dict]): The transcription segments. Each dict should have a 'text' and \n",
    "            'start' and 'end' keys for the transcription text and start and end times, respectively.\n",
    "    \n",
    "    Returns:\n",
    "        List[dict]: A list of dictionaries containing tokenized sentences with 'text', 'tokens', 'start',\n",
    "            and 'end' keys for the sentence text, tokenized form, and start and end times, respectively.\n",
    "    \"\"\"\n",
    "    # Initialize NLP tokenizer and maximum length of tokens\n",
    "    NLP_TOKENIZER = AutoTokenizer.from_pretrained(NLP_ARCH)\n",
    "    NLP_MAXLEN = NLP_TOKENIZER.model_max_length - 5\n",
    "    # Initialize list to store tokenized sentences and current sentence data\n",
    "    sent_tokens = []\n",
    "    d = {}\n",
    "    # Tokenize each transcription segment\n",
    "    for seg in asr_result:\n",
    "        seg_tokens = NLP_TOKENIZER(seg[\"text\"], add_special_tokens=False)['input_ids']\n",
    "        # If current tokens plus segment tokens exceed maximum length, add current sentence data to list\n",
    "        if len(seg_tokens) + len(d.get('tokens', [])) >= NLP_MAXLEN:\n",
    "            sent_tokens.append(d)\n",
    "            d = {}\n",
    "        # If current sentence data does not have a start time, set it\n",
    "        if 'start' not in d.keys(): \n",
    "            d['start'] = seg['start']\n",
    "        # Add segment text and tokens to current sentence data\n",
    "        curr_tokens = d.get('tokens', [])\n",
    "        curr_text = d.get('text', \"\")\n",
    "        d['text'] = curr_text + seg['text']\n",
    "        d['tokens'] = curr_tokens + seg_tokens\n",
    "        d['end'] = seg['end']\n",
    "\n",
    "    # Add final sentence data to list\n",
    "    sent_tokens.append(d)\n",
    "    return sent_tokens\n",
    "\n",
    "\n",
    "def get_transcript_summary(transcript_file: str, summary_lengths: int = 128):\n",
    "    \"\"\"\n",
    "    Generate a summary of a transcript and save it to a file.\n",
    "    \n",
    "    Parameters:\n",
    "        transcript_file (str): The file path of the transcript.\n",
    "        summary_lengths (int): The maximum length of the summary.\n",
    "    \n",
    "    Returns:\n",
    "        str: The file path of the summary.\n",
    "    \"\"\"\n",
    "    # Load the transcript from a file\n",
    "    transcript = load_csv_to_transcript(transcript_file)\n",
    "    \n",
    "    # Tokenize the transcript and add timestamps\n",
    "    timestamped_sentences = tokenize_with_timestamps(transcript)\n",
    "    \n",
    "    print(\"[NLP] Generating summary of transcription\")\n",
    "    \n",
    "    # Extract the sentences from the timestamped transcript\n",
    "    sentences = [sent['text'] for sent in timestamped_sentences]\n",
    "    \n",
    "    # Initialize the summarization pipeline\n",
    "    summarizer = pipeline(\"summarization\", model=NLP_ARCH)\n",
    "    \n",
    "    # Generate summaries for the sentences\n",
    "    summaries = summarizer(sentences, max_length=summary_lengths, min_length=20, do_sample=False)\n",
    "    \n",
    "    # Add the summaries to the original timestamped sentences\n",
    "    for a, b in zip(timestamped_sentences, summaries):\n",
    "        a['summary'] = b['summary_text']\n",
    "    \n",
    "    # Save the timestamped summaries to a file\n",
    "    summary_file = os.path.dirname(transcript_file)+\"/summary.csv\"\n",
    "    save_transcript_to_csv(timestamped_sentences, summary_file)\n",
    "    print(\"[NLP] Video summary saved at \", summary_file)\n",
    "\n",
    "    return summary_file\n",
    "\n",
    "summary = get_transcript_summary(transcript_path, SUMMARY_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_timestamped_summaries(summary)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
