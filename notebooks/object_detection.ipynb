{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import requests\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set options\n",
    "\n",
    "IMAGE_URL = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_dict():\n",
    "    idx_to_labels_url = \"https://gist.githubusercontent.com/suraj813/1fe4c9dd0bc7e1dd1ce79462712ac9ce/raw/0e2c65813946769a375d673a34a1c0236b0505f1/coco_idx_to_labels.txt\"\n",
    "    r = requests.get(idx_to_labels_url).text\n",
    "    return ast.literal_eval(r)\n",
    "\n",
    "def load_input(img_path):\n",
    "    image = Image.open(img_path)\n",
    "    image = torchvision.transforms.ToTensor()(image)\n",
    "    return image\n",
    "\n",
    "def count_objects(model_output):\n",
    "    _, labels, confidence = model_output[0].values()\n",
    "    label_map = get_mapping_dict()\n",
    "    detected_objects = []\n",
    "    \n",
    "    # filter out low-confidence predictions\n",
    "    confidence_threshold = 0.85\n",
    "    for label, confidence in zip(labels.tolist(), confidence.tolist()):\n",
    "        if confidence > confidence_threshold:\n",
    "            classname = label_map[str(label)]\n",
    "            detected_objects.append((classname, confidence,))\n",
    "    \n",
    "    counts = Counter([x[0] for x in detected_objects])\n",
    "    return detected_objects, counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pretrained torchvision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    # Set it to `eval` mode because we aren't training the model\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an image to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    if url.startswith(\"http\"):\n",
    "        r = requests.get(url).content\n",
    "        open(\"input.jpg\", \"wb\").write(r)\n",
    "        url = \"input.jpg\"\n",
    "    return url\n",
    "    \n",
    "img_path = download_image(IMAGE_URL)\n",
    "Image.open(img_path).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the image for inference\n",
    "- we convert the human-readable image into a model-readable tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = load_input(img_path)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batchify\n",
    "- Since the operations on each image are identical and independent of each other, they can be performed in parallel. This is why inputs to deep learning models are batches of images (or text or audio or whatever your model consumes)\n",
    "- In our case, we are interested in predictions on a single image. So we create a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = [img_tensor]  # singleton list\n",
    "X = torch.tensor(list_of_images)  # input batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference on the image\n",
    "- Pass the input batch through the model\n",
    "- The model returns an output batch, one entry for each input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(X)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process output\n",
    "For each object detected in an input image, the model returns to us:\n",
    "- what it thinks the object is (_label_)\n",
    "- how confident it is about it's prediction (_confidence_)\n",
    "- co-ordinates of where in the image is the detected object (_bounding box_)\n",
    "\n",
    "In our function, we are only interested in the objects the model detects with high confidence. Further, there might be multiple occurences of an object in the image; we also want the function to count how many times each object appears in the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_detected_objects(model_output, confidence_threshold):\n",
    "    bbox, labels, confidence = model_output.values()\n",
    "    label_map = get_mapping_dict()\n",
    "    detected_objects = []\n",
    "    \n",
    "    # filter out low-confidence predictions\n",
    "    for label, confidence in zip(labels.tolist(), confidence.tolist()):\n",
    "        if confidence > confidence_threshold:\n",
    "            classname = label_map[str(label)]\n",
    "            detected_objects.append((classname, confidence,))\n",
    "    \n",
    "    counts = Counter([x[0] for x in detected_objects])\n",
    "    return detected_objects, counts \n",
    "    \n",
    "\n",
    "detected_objects, counts = count_detected_objects(predictions[0], confidence_threshold=0.85)   \n",
    "\n",
    "print(\"Detected objects:\")\n",
    "print(\"=\"*20)\n",
    "pprint(detected_objects)\n",
    "print()\n",
    "\n",
    "print(\"Count of objects:\")\n",
    "print(\"=\"*20)\n",
    "pprint(counts)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
